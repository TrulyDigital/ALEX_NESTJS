# Entorno de Kafka con SFTP y Kafka Connect

Este proyecto configura un entorno local de desarrollo para procesar archivos CSV desde un servidor SFTP utilizando Apache Kafka y Kafka Connect. La configuraciÃ³n imita un entorno productivo con una arquitectura escalable.

## Estructura del Proyecto

```
ðŸ“‚ /kafka_process_files_1
 |
 â”œâ”€â”€ ðŸ“‚ server_kafka
 |   |
 â”‚   â”œâ”€â”€ ðŸ“‚ broker1     # Volumen para almacenar datos de Kafka
 â”‚   â”œâ”€â”€ ðŸ“‚ broker2     # Volumen para almacenar datos de Kafka
 â”‚   â”œâ”€â”€ ðŸ“‚ zookeeper   # Volumen para datos de Zookeeper
 |
 â”œâ”€â”€ ðŸ“‚ server_sftp
 |   |               
 â”‚   â”œâ”€â”€ ðŸ“‚ pry_terminals
 |   |    |
 â”‚   |    â”œâ”€â”€ ðŸ“‚ 1_unprocessed  # Archivos CSV de entrada
 â”‚   |    â”œâ”€â”€ ðŸ“‚ 2_processed  # Archivos procesados
 â”‚   |    â”œâ”€â”€ ðŸ“‚ error          # Archivos con errores
 |
 â”œâ”€â”€ ðŸ“‚ server_kafka_connect
 |   |
 â”‚   â”œâ”€â”€ ðŸ“‚ config        # ConfiguraciÃ³n del conector
 â”‚   â”œâ”€â”€ ðŸ“‚ connectors    # Plugins de conectores
 â”‚   â”œâ”€â”€ ðŸ“‚ errors        # Errores
 |
 â”œâ”€â”€ app.yaml       # ConfiguraciÃ³n principal de Docker Compose
 â”œâ”€â”€ setup.sh            # Script de inicializaciÃ³n
 â”œâ”€â”€ sample.csv          # Archivo CSV de ejemplo
```

## Componentes

1. **Zookeeper**: Necesario para la gestiÃ³n de Kafka
2. **Kafka Broker**: Broker de Apache Kafka con configuraciÃ³n de una particiÃ³n
3. **Servidor SFTP**: Servidor ligero para el intercambio de archivos
4. **Kafka Connect**: Para conectar Kafka con fuentes externas (SFTP)
5. **Schema Registry**: Para gestionar esquemas (opcional)
6. **Kafka UI**: Interfaz web para monitorizar Kafka

## Requisitos Previos

- Docker y Docker Compose
- Permisos para ejecutar scripts bash

## ConfiguraciÃ³n Inicial

1. Clona este repositorio
2. Ejecuta el script de configuraciÃ³n:

```bash
chmod +x setup.sh
./setup.sh
```

Este script:
- Crea los directorios necesarios
- Establece los permisos adecuados
- Inicia los servicios Docker
- Crea el tÃ³pico Kafka
- Registra el conector SFTP-CSV

## Uso del Entorno

### Colocar Archivos CSV para Procesamiento

1. Coloca tus archivos CSV en la carpeta `server_sftp/pry_terminals/1_unprocessed`
2. Alternativamente, conÃ©ctate via SFTP:
   - Host: localhost
   - Puerto: 2222
   - Usuario: sftp_user
   - ContraseÃ±a: sftp_password
   - Ruta: `/pry_terminals/1_unprocessed`

### Verificar el Procesamiento

1. Los archivos procesados se moverÃ¡n a `server_sftp/pry_terminals/2_unprocessed`
2. Los registros se enviarÃ¡n al tÃ³pico `csv-to-row-topic`
3. Puedes verificar los mensajes usando Kafka UI: http://localhost:8080

### Monitoreo

- **Kafka UI**: http://localhost:8080
- **Kafka Connect REST API**: http://localhost:8083
- **Schema Registry**: http://localhost:8081

## Escalabilidad

Este entorno estÃ¡ preparado para ser escalado:

- Para aÃ±adir un segundo broker, descomentar la secciÃ³n correspondiente en `app-stack.yml`
- Actualizar `KAFKA_REPLICATION_FACTOR` y otras configuraciones relacionadas

## Troubleshooting

Si encuentras problemas:

1. Verifica los logs de los contenedores:
   ```bash
   docker logs kafka-connect
   ```

2. Comprueba el estado del conector:
   ```bash
   curl http://localhost:8083/connectors/sftp-source-csv-connector/status
   ```

3. Reinicia un servicio especÃ­fico:
   ```bash
   docker-compose -f app-stack.yml restart kafka-connect
   ```

## Limpieza

Para detener y eliminar todos los servicios:

```bash
docker-compose -f app-stack.yml down
```

Para eliminar tambiÃ©n los volÃºmenes:

```bash
docker-compose -f app-stack.yml down -v
```